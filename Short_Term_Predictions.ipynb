{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn as sk\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_folder = 'C:\\\\Users\\\\EMBA\\\\Documents\\\\Technical_Training\\\\Machine Learning - Stock Market trading\\\\Yes Bank\\\\Data\\\\Featurized\\\\'\n",
    "target_folder = 'C:\\\\Users\\\\EMBA\\\\Documents\\\\Technical_Training\\\\Machine Learning - Stock Market trading\\\\Yes Bank\\\\Model\\\\'\n",
    "#file_name = 'Consolidated_data_set.csv'\n",
    "file_name = 'YESBANK.csv'\n",
    "model_name ='Comprehensive_model.sav'\n",
    "source_file_path = source_folder +  file_name\n",
    "target_file_path = target_folder + model_name\n",
    "stock_data = pd.read_csv(source_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stock_data = stock_data.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stock_data.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attr_cols = (stock_data.columns).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_cols = []\n",
    "signal_cols = []\n",
    "for i in attr_cols:\n",
    "    attr_list=[]\n",
    "    attr_list = i.split('_')\n",
    "    if 'RBC' in attr_list or 'DBC' in attr_list or 'RBCV' in attr_list or 'DBCV' in attr_list  or 'Add' in attr_list:\n",
    "        feature_cols.append(i)\n",
    "    if 'Signal' in attr_list and 'V' not in attr_list:\n",
    "        signal_cols.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#features = stock_data[['% Change', '% V_Change', \n",
    "#        'Roll_Change_30', 'Roll_VChange_30', 'DB_CMax_30', 'DB_CMin_30', 'DB_CMean_30', 'DB_CVMax_30', 'DB_CVMin_30', 'DB_CVMean_30', \n",
    "#        'Roll_Change_50', 'Roll_VChange_50', 'DB_CMax_50', 'DB_CMin_50', 'DB_CMean_50', 'DB_CVMax_50', 'DB_CVMin_50', 'DB_CVMean_50', \n",
    "#       'Roll_Change_150', 'Roll_VChange_150', 'DB_CMax_150', 'DB_CMin_150', 'DB_CMean_150', 'DB_CVMax_150', 'DB_CVMin_150', 'DB_CVMean_150',\n",
    "#       'Roll_Change_200', 'Roll_VChange_200', 'DB_CMax_200', 'DB_CMin_200', 'DB_CMean_200', 'DB_CVMax_200', 'DB_CVMin_200', 'DB_CVMean_200']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#features = stock_data[['% Change',  \n",
    "#        'Roll_Change_30', 'DB_CMax_30', 'DB_CMin_30', 'DB_CMean_30', 'DB_CVMean_30', \n",
    "#        'Roll_Change_50', 'DB_CMax_50', 'DB_CMin_50', 'DB_CMean_50',  'DB_CVMean_50',\n",
    "#        'Roll_Change_150', 'DB_CMax_150', 'DB_CMin_150', 'DB_CMean_150', 'DB_CVMean_150',\n",
    "#        'Roll_Change_200', 'DB_CMax_200', 'DB_CMin_200', 'DB_CMean_200', 'DB_CVMean_200']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DF_Signal_Buy_10',\n",
       " 'DF_Signal_Sell_10',\n",
       " 'DF_Signal_Buy_15',\n",
       " 'DF_Signal_Sell_15',\n",
       " 'DF_Signal_Buy_20',\n",
       " 'DF_Signal_Sell_20',\n",
       " 'DF_Signal_Buy_25',\n",
       " 'DF_Signal_Sell_25',\n",
       " 'DF_Signal_Buy_30',\n",
       " 'DF_Signal_Sell_30',\n",
       " 'DF_Signal_Buy_50',\n",
       " 'DF_Signal_Sell_50',\n",
       " 'DF_Signal_Buy_150',\n",
       " 'DF_Signal_Sell_150',\n",
       " 'DF_Signal_Buy_200',\n",
       " 'DF_Signal_Sell_200']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = stock_data[feature_cols]\n",
    "features = features[200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_target.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test_target.hist()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_data(train_data,test_data):\n",
    "    from sklearn.preprocessing import normalize\n",
    "    train_data = normalize(train_data,axis=0)\n",
    "    #train_target = normalize(train_target)\n",
    "    test_data = normalize(test_data,axis=0)\n",
    "    #test_target = normalize(test_target)\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_predictions_for_t_column(model_performance,t_signal,first_run,features,train_data,train_target,test_data,test_target):\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    import operator\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import sklearn as sk\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    features_columns = features.columns\n",
    "    baseline = len(test_target[test_target == 0])/len(test_target)\n",
    "    \n",
    "    for penalty in ('l1','l2'):\n",
    "        #for maxiter in (1000,2000,3000,4000,5000,10000,50000,100000):\n",
    "        for maxiter in (4000,5000):\n",
    "            #for tolerance in (1e+10,1e+8,1e+6,1e+4,1e+2,1e+0,1e-2,1e-4,1e-6,1e-8,1e-10,1e-12):\n",
    "            for tolerance in (1e-4,1e-6,1e-8,1e-10,1e-12):\n",
    "                #print ('processing '  +str(t_signal))\n",
    "                model = sk.linear_model.LogisticRegression(penalty=penalty,max_iter=maxiter,tol=tolerance)\n",
    "                #model.fit(train_data.as_matrix(),train_target.as_matrix())\n",
    "                model.fit(train_data,train_target)\n",
    "                #model.coef_\n",
    "                #features_columns\n",
    "                map_coeff_columns = dict()\n",
    "                for i in range(len(features_columns)):\n",
    "                    map_coeff_columns[features_columns[i]] = model.coef_[0][i]\n",
    "                #print (map_coeff_columns)\n",
    "                sorted_map_coeff_columns = sorted(map_coeff_columns.items(),key=operator.itemgetter(1),reverse=True)\n",
    "                #sorted_map_coeff_columns\n",
    "                #accuracy = accuracy_score(y_true=test_target.as_matrix(), y_pred=model.predict(test_data))\n",
    "                accuracy = accuracy_score(y_true=test_target, y_pred=model.predict(test_data))\n",
    "                #print (\"Test Accuracy: %s\" % accuracy)\n",
    "                #print (\"Baseline accuracy (majority class classifier): %s\" % baseline)\n",
    "                predicted_signal = model.predict(test_data)\n",
    "                cmat = confusion_matrix(y_true=test_target.as_matrix(),\n",
    "                                        y_pred=model.predict(test_data),\n",
    "                                        labels=model.classes_)    # use the same order of class as the LR model.\n",
    "                #print (' target_label | predicted_label | count ')\n",
    "                #print ('--------------+-----------------+-------')\n",
    "                # Print out the confusion matrix.\n",
    "                # NOTE: Your tool may arrange entries in a different order. Consult appropriate manuals.\n",
    "                false_action = 0\n",
    "                false_no_action = 0\n",
    "                true_action = 0\n",
    "                true_no_action = 0\n",
    "                for i, target_label in enumerate(model.classes_):\n",
    "                    for j, predicted_label in enumerate(model.classes_):\n",
    "                        #print ('{0:^13} | {1:^15} | {2:5d}'.format(target_label, predicted_label, cmat[i,j]))\n",
    "                        if target_label == predicted_label:\n",
    "                            if target_label ==0:\n",
    "                                true_no_action = cmat[i,j]\n",
    "                            else:\n",
    "                                true_action = cmat[i,j]\n",
    "                        elif target_label == 0:\n",
    "                            false_action = cmat[i,j]\n",
    "                        else:\n",
    "                            false_no_action = cmat[i,j]\n",
    "                        if (true_action + false_action) == 0:\n",
    "                            precision = 0\n",
    "                        \n",
    "                            precision = true_action / (true_action + false_action)\n",
    "                        recall = true_action/ (true_action + false_no_action)\n",
    "\n",
    "                # save the model to disk\n",
    "                model_name = 'Yesbank_model_' +str(t_signal) +str('_') +str(penalty) +str('_') + str (maxiter) +str('_') + str(tolerance) +str('.sav')\n",
    "                target_file_path = target_folder + model_name\n",
    "                pickle.dump(model, open(target_file_path, 'wb'))\n",
    "                new_row = {'Stock':['YesBank'],'Date':['2017-11-21'],'Prediction':t_signal,'Penalty':penalty,'Max_Iter':maxiter,'Tolerance':tolerance,'Model_Coeff': str(sorted_map_coeff_columns),'Accuracy':accuracy,'Majority_Class':baseline,'Confusion_Matrix':str(cmat),'Model_Classes':str(model.classes_),'CM_True_No_Action':true_no_action,'CM_True_Buy/Sell':true_action,'CM_False_Buy/Sell':false_action,'CM_False_Inaction':false_no_action,'Precision':precision,'Recall':recall}\n",
    "\n",
    "                model_performance = model_performance.append(new_row,ignore_index=True)\n",
    "\n",
    "                #model_name ='Yesbank_model_OneVsRest_2017-10-26.sav'\n",
    "                #target_file_path = target_folder + model_name\n",
    "                #pickle.dump(model_OneVsRest, open(target_file_path, 'wb'))\n",
    "    return model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#precision = model.evaluate(test_data, metric='precision')['precision']\n",
    "#print \"Precision on test data: %s\" % precision\n",
    "\n",
    "#from sklearn.metrics import precision_score\n",
    "#precision = precision_score(y_true=test_target.as_matrix(), \n",
    "#                            y_pred=model.predict(test_data))\n",
    "#print (\"Precision on test data: %s\" % precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#recall = model.evaluate(test_data, metric='recall')['recall']\n",
    "#print \"Recall on test data: %s\" % recall\n",
    "\n",
    "#from sklearn.metrics import recall_score\n",
    "#recall = recall_score(y_true=test_target.as_matrix(),\n",
    "#                      y_pred=model.predict(test_data))\n",
    "#print (\"Recall on test data: %s\" % recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.predict_log_proba(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.predict_proba(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def apply_threshold(probabilities, threshold, predicted_signal):\n",
    "    ### YOUR CODE GOES HERE\n",
    "    # +1 if >= threshold and -1 otherwise.\n",
    "#    prediction = pd.Series(len(probabilities))\n",
    "#    for i in range(len(probabilities)):\n",
    "#        if probabilities[i] > threshold:\n",
    "#            prediction[i] = predicted_signal[i]\n",
    "#        #elif predicted_signal[i] == 0:\n",
    "        #    prediction[i] = 0\n",
    "        #elif predicted_signal[i] == -1:\n",
    "        #    prediction[i] = -1\n",
    "#        else:\n",
    "#            prediction[i] = 2 # unless strong signal, take no position (buy/sell)\n",
    "#    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#probabilities = model.predict_proba(test_data)[:,1]\n",
    "#predictions_with_default_threshold = apply_threshold(probabilities, 0.5, predicted_signal)\n",
    "#predictions_with_high_threshold = apply_threshold(probabilities, 0.8, predicted_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.metrics import confusion_matrix\n",
    "#cmat = confusion_matrix(y_true=test_target.as_matrix(),\n",
    "#                        y_pred=predictions_with_high_threshold,\n",
    "#                        labels=model.classes_)    # use the same order of class as the LR model.\n",
    "#print (' target_label | predicted_label | count ')\n",
    "#print ('--------------+-----------------+-------')\n",
    "# Print out the confusion matrix.\n",
    "# NOTE: Your tool may arrange entries in a different order. Consult appropriate manuals.\n",
    "#for i, target_label in enumerate(model.classes_):\n",
    "#    for j, predicted_label in enumerate(model.classes_):\n",
    "#        print ('{0:^13} | {1:^15} | {2:5d}'.format(target_label, predicted_label, cmat[i,j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#type(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prob_df = pd.DataFrame(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prob_df[0].hist()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prob_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import label_binarize\n",
    "#from sklearn import svm, datasets\n",
    "\n",
    "# Use label_binarize to be multi-label like settings\n",
    "#Y = label_binarize(target, classes=[-1, 0, 1])\n",
    "#n_classes = Y.shape[1]\n",
    "#X = features\n",
    "\n",
    "# Split into training and test\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.25, random_state=42)\n",
    "\n",
    "# We use OneVsRestClassifier for multi-label prediction\n",
    "#from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Run classifier\n",
    "#classifier = OneVsRestClassifier(svm.LinearSVC(random_state=42))\n",
    "#model_OneVsRest = classifier.fit(X_train, Y_train)\n",
    "#y_score = classifier.decision_function(X_test)\n",
    "#y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.metrics import average_precision_score\n",
    "#from sklearn.metrics import average_recall_score\n",
    "#average_precision = average_precision_score(Y_test, y_score)\n",
    "#average_recall = average_recall_score(Y_test,y_score)\n",
    "\n",
    "#print('Average precision-recall score: {0:0.2f}'.format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.metrics import precision_recall_curve\n",
    "#from sklearn.metrics import average_precision_score\n",
    "\n",
    "# For each class\n",
    "#precision = dict()\n",
    "#recall = dict()\n",
    "#average_precision = dict()\n",
    "#for i in range(n_classes):\n",
    "#    precision[i], recall[i], _ = precision_recall_curve(Y_test[:, i],\n",
    "#                                                        y_score[:, i])\n",
    "#    average_precision[i] = average_precision_score(Y_test[:, i], y_score[:, i])\n",
    "\n",
    "# A \"micro-average\": quantifying score on all classes jointly\n",
    "#precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(Y_test.ravel(),\n",
    "#    y_score.ravel())\n",
    "#average_precision[\"micro\"] = average_precision_score(Y_test, y_score,\n",
    "#                                                     average=\"micro\")\n",
    "#print('Average precision score, micro-averaged over all classes: {0:0.2f}'\n",
    "\n",
    "#      .format(average_precision[\"micro\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#match = 0\n",
    "#minus_1 = 0\n",
    "#zero = 0\n",
    "#plus_1 = 0\n",
    "#unknown = 0\n",
    "#for i in range(3):\n",
    "#    for x in range(len(Y_test)):\n",
    "#        if Y_test[x][i] == y_pred[x][i]:\n",
    "#            match = match + 1\n",
    "#        elif y_pred[x][0] == 1:\n",
    "#            minus_1 = minus_1 + 1\n",
    "#        elif y_pred[x][1] == 1:\n",
    "#            zero = zero + 1\n",
    "#        elif y_pred[x][2] == 1:\n",
    "#            plus_1 = plus_1 + 1\n",
    "#        else:\n",
    "#            unknown = unknown + 1\n",
    "#    print (str(i) +' matched ' +str(match))\n",
    "#    print (str(minus_1) +' ' +str(zero) +' ' +str(plus_1) +' ' +str(unknown))\n",
    "#    match = 0\n",
    "#    minus_1 = 0\n",
    "#    zero = 0\n",
    "#    plus_1 = 0\n",
    "#    unknown = 0\n",
    "#print ('total rows ' +str(len(Y_test))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model_read = pickle.load(open(target_file_path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#a = y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#no_pred = 0\n",
    "#for i in range(len(y_pred)):\n",
    "#    if y_pred[i].sum() > 1:\n",
    "#        no_pred += 1\n",
    "#        print ('no pred ' +str(y_pred[i]))\n",
    "#print ('no pred ' +str(no_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-ba86ce5b8841>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mmodel_performance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_predictions_for_t_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_performance\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt_signal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfirst_run\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_target\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mfirst_run\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-3ce0017b533a>\u001b[0m in \u001b[0;36mrun_predictions_for_t_column\u001b[1;34m(model_performance, t_signal, first_run, features, train_data, train_target, test_data, test_target)\u001b[0m\n\u001b[0;32m     53\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m                             \u001b[0mfalse_no_action\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcmat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m                         \u001b[0mprecision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrue_action\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrue_action\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfalse_action\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m                         \u001b[0mrecall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrue_action\u001b[0m\u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrue_action\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfalse_no_action\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "first_run = True\n",
    "new_row = {'Stock':['YesBank'],'Date':['2017-11-21'],'Prediction':[0],'Penalty':[0],'Max_Iter':[0],'Tolerance':[0],'Model_Coeff': [0],'Accuracy':[0],'Majority_Class':[0],'Confusion_Matrix':[0],'Model_Classes':[0],'CM_True_No_Action':[0],'CM_True_Buy/Sell':[0],'CM_False_Buy/Sell':[0],'CM_False_Inaction':[0],'Precision':[0],'Recall':[0]}\n",
    "model_performance = pd.DataFrame(data=new_row,index=None,columns=('Stock','Date','Prediction', 'Penalty','Max_Iter','Tolerance','Model_Coeff','Accuracy','Majority_Class','Confusion_Matrix','CM_True_No_Action','CM_True_Buy/Sell','CM_False_Buy/Sell','CM_False_Inaction','Precision','Recall'))\n",
    "\n",
    "for t_signal in signal_cols:\n",
    "    #print (t_signal)\n",
    "    target = stock_data[t_signal]\n",
    "    target = target[200:]\n",
    "    train_data, test_data, train_target, test_target = train_test_split(features, target, test_size=0.25, random_state=42)\n",
    "    train_data, test_data = normalize_data(train_data,test_data)\n",
    "    model_performance = run_predictions_for_t_column(model_performance,t_signal,first_run,features,train_data,train_target,test_data,test_target)\n",
    "    first_run = False  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = 'Model_Performance_2017-11-21.csv'\n",
    "target_file_path = target_folder + file_name\n",
    "model_performance.to_csv(target_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
